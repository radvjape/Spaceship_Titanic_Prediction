## About this Part

Congrats!
You have reached the last Part of this Sprint.
In this Part, you will put what you learned during this and the previous Sprints into practice.
As the final assignment of this Sprint you will participate in a Kaggle competition .
You will have to apply all you have learned about training machine learning models to complete this task.
Our expectation is that you'll use your own judgment on how to perform the analysis and select the most important avenues of modeling, statistical testing, and exploration.
You'll have to iteratively try to find patterns in the data, raise hypotheses and use your data analysis skills to get answers.

P.S. we don't expect this project to be perfect - you will continue to improve your skills and there will be many projects for you to apply your newly gained skills in the future.
For now just use what you have learned and try your best!

*Note:* [advice on building your portfolio](https://turingcollege.atlassian.net/wiki/spaces/DLG/pages/1002307695/Portfolio+Items)

## Context

Participating in Kaggle competitions is an extremely valuable practice for any aspiring data scientist.
While you have encountered a number of datasets in Kaggle, this is the first time that you are asked to participate in a competition.
The main difference between Kaggle competitions and Kaggle datasets is that competitions provide a public leaderboard that displays how well the competitors are doing on a (hidden) test dataset.

In this Part you will try to get a high score on the [Spaceship Titanic competition](https://www.kaggle.com/competitions/spaceship-titanic).
Spaceship Titanic is a successor to the Titanic - one of the most famous competitions (and datasets) of all time.
Spaceship Titanic dataset is a huge improvement over the Titanic.
It requires you to work with numeric, categorical, and NLP data.
There are a lot of traps that might make your model not perform as well as it can.
There are also a lot of opportunities to get your model to perform better with smart feature engineering.

## Objectives for this Part

- Practice performing EDA.
- Practice using various types of machine learning models.
- Practice building ensembles of machine learning models.
- Practice using hyperparameter tuning.
- Practice using AutoML tools.
- Practice visualizing data with Matplotlib & Seaborn.
- Practice reading data, performing queries, and filtering data.

## Requirements

- Perform exploratory data analysis. This should include creating statistical summaries and charts, testing for anomalies, checking for correlations and other relations between variables, and other EDA elements.
- Perform statistical inference. This should include defining the target population, forming multiple statistical hypotheses and constructing confidence intervals, setting the significance levels, conducting z or t-tests for these hypotheses.
- Apply various machine learning models to predict the target variables based on your proposed plan. You should use hyperparameter tuning, model ensembling, the analysis of model selection, and other methods. The decision where to use and not to use these techniques is up to you, however, they should be aligned with your team's objectives.
- Submit your solution to Kaggle. Repeat until you get a score of 0.79 or above.
- Provide clear explanations in your notebook. Your explanations should inform the reader what you are trying to achieve, what results you got, and what these results mean.
- Provide suggestions about how your analysis and models can be improved.

## Evaluation Criteria

- Adherence to the requirements. How well did you meet the requirements?
- Depth of your analysis. Did you just skim the surface, or did you explored the dataset in-depth?
- Model's performance. How well did your model perform the predictions?
- Visualization quality. Did you use charts effectively to visualize patterns in the data? Are your visualizations properly labeled? Did you use colors effectively? Did you adhere to the principle of proportional ink?
- Code quality. Was your code well-structured? Did you use the appropriate levels of abstraction? Did you remove commented-out and unused code? Did you adhere to the PEP8?
- Code performance. Did you use suitable algorithms and data structures to solve the problems?

## Project Review

During your project review, you should present your project as if talking to your friend, who is a senior data scientist.
You will have to find the right balance between explaining the business side and the technical aspects of your work.
You can assume that your friend has a strong understanding of and are very interested in the machine learning competitions, so be sure to clearly explain what new insights you've found while trying to build a model for this competition and which directions look the most promising for further research.

During a project review, you may get asked questions that test your understanding of covered topics.

- What dimensionality reduction algorithms do you know? What are their differences?
- What is the curse of dimensionality?
- What hyperparameter tuning strategies do you know? What are their advantages compared to Grid Search and Random Search?
- Explain how SMOTE algorithm works? In which circumstances is this algorithm the most useful and in which it falls short?
- What is AutoML? Why is it important?
